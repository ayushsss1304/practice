# Ensure inline plotting
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import precision_recall_curve, classification_report, accuracy_score
import os

# Create results directory
os.makedirs("results", exist_ok=True)

# Load and prepare Titanic dataset
df = sns.load_dataset("titanic")
df = df[["sex", "age", "fare", "class", "survived"]].dropna()

# Convert categorical features to numeric
df["sex"] = df["sex"].map({"male": 0, "female": 1})
df["class"] = df["class"].map({"Third": 3, "Second": 2, "First": 1})

# Define features and target
X = df.drop("survived", axis=1)
y = df["survived"]

# Split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
lr = LogisticRegression(max_iter=200, random_state=42)
rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)  # Increased complexity for Random Forest

# Train models
lr.fit(x_train, y_train)
rf.fit(x_train, y_train)

# Predict using both models
y_pred_lr = lr.predict(x_test)
y_pred_rf = rf.predict(x_test)

# --- 1. Confusion Matrices ---
# Logistic Regression
cm_lr = confusion_matrix(y_test, y_pred_lr)
disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr)
disp_lr.plot()
plt.title("Logistic Regression Confusion Matrix")
plt.show()  # Make sure it shows in Jupyter
plt.savefig("results/conf_matrix_lr.png")
plt.close()

# Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)
disp_rf.plot()
plt.title("Random Forest Confusion Matrix")
plt.show()  # Make sure it shows in Jupyter
plt.savefig("results/conf_matrix_rf.png")
plt.close()

# --- 2. Precision-Recall Curves ---
# Logistic Regression
y_scores_lr = lr.predict_proba(x_test)[:, 1]
precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_scores_lr)

# Random Forest
y_scores_rf = rf.predict_proba(x_test)[:, 1]
precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_scores_rf)

# Plot both Precision-Recall curves
plt.figure()
plt.plot(recall_lr, precision_lr, label="Logistic Regression")
plt.plot(recall_rf, precision_rf, label="Random Forest")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()  # Make sure it shows in Jupyter
plt.savefig("results/precision_recall_comparison.png")
plt.close()

# --- 3. Model Performance Comparison ---
# Print classification reports
print("=== Logistic Regression ===")
print(classification_report(y_test, y_pred_lr))

print("=== Random Forest ===")
print(classification_report(y_test, y_pred_rf))

# Calculate and compare accuracies
acc_lr = accuracy_score(y_test, y_pred_lr)
acc_rf = accuracy_score(y_test, y_pred_rf)

print(f"Accuracy - Logistic Regression: {acc_lr:.2f}")
print(f"Accuracy - Random Forest: {acc_rf:.2f}")
